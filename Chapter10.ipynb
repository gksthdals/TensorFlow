{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTJB2UgUbLS-"
      },
      "source": [
        "# 10.1 Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1prEpDaubVGs"
      },
      "outputs": [],
      "source": [
        "# 단어 및 문장 간 관련성 계산\n",
        "# 의미적 혹은 문법적 정보의 함축"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aM4LAKsWb09n"
      },
      "source": [
        "## 10.1.1 Sparse Representation based Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxEXw14qb7ZL",
        "outputId": "c5003b12-ea14-498f-c320-ce90e11c9143"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([2, 2, 1, 0, 1, 0])"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "class2 = pd.read_csv('data/chap10/class2.csv')\n",
        "\n",
        "from sklearn import preprocessing\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "onehot_encoder = preprocessing.OneHotEncoder()\n",
        "\n",
        "train_x = label_encoder.fit_transform(class2['class2'])\n",
        "train_x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cfnyl8WjccQM"
      },
      "outputs": [],
      "source": [
        "\"\"\" One-hot Encoding의 단점 \n",
        "\n",
        "1. 단어끼리의 관계성(유의어, 반의어) 업이 서로 독립적인 관계\n",
        "2. 차원이 너무 커지는 문제가 발생\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5o-rUqHNcy1r"
      },
      "source": [
        "## 10.1.2 Counting based Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49hzdW3_c8gR",
        "outputId": "ca84c159-abaa-47a1-ebd6-6f2d616305ed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'this': 13,\n",
              " 'is': 7,\n",
              " 'last': 8,\n",
              " 'chance': 2,\n",
              " 'and': 0,\n",
              " 'if': 6,\n",
              " 'you': 15,\n",
              " 'do': 3,\n",
              " 'not': 10,\n",
              " 'have': 5,\n",
              " 'will': 14,\n",
              " 'never': 9,\n",
              " 'get': 4,\n",
              " 'any': 1,\n",
              " 'one': 11,\n",
              " 'please': 12}"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Corpus에 counter vector 적용\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "corpus = [\n",
        "          'This is last chance.',\n",
        "          'and if you do not have this chance.',\n",
        "          'you will never get any chance.',\n",
        "          'will you do get this one?',\n",
        "          'please, get this chance',\n",
        "]\n",
        "\n",
        "vect = CountVectorizer()\n",
        "vect.fit(corpus)\n",
        "vect.vocabulary_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIznLqB8derw",
        "outputId": "4b596fed-83e8-4f5d-9e50-54000e8cf94a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1]])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vect.transform(['you will never get any chance.']).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50YDT4vndpV9",
        "outputId": "30481145-e86d-42c5-82fd-c4793b74d914"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'last': 6,\n",
              " 'chance': 1,\n",
              " 'if': 5,\n",
              " 'you': 11,\n",
              " 'do': 2,\n",
              " 'not': 8,\n",
              " 'have': 4,\n",
              " 'will': 10,\n",
              " 'never': 7,\n",
              " 'get': 3,\n",
              " 'any': 0,\n",
              " 'one': 9}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vect = CountVectorizer(stop_words=[\"and\", \"is\", \"please\", \"this\"]).fit(corpus)\n",
        "vect.vocabulary_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TQCIc-J0d54E"
      },
      "outputs": [],
      "source": [
        "# TF-IDF : Term Frequency-Inverse Document Frequency\n",
        "\n",
        "# TF : 특정 문서 d에서 특정 단어 t의 등장 횟수\n",
        "# DF : 특정 단어 t가가 포함된 문서 개수\n",
        "# IDF : Inverse Document Frequency\n",
        "\n",
        "# 키워드 검색을 기반으로 하는 검색 엔진\n",
        "# 중요 키워드 분석\n",
        "# 검색 엔진에서 검색 결과의 순위를 결정 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDZoixx93kAN",
        "outputId": "66855650-ff50-4964-991c-7a2e09188fb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "유사도를 위한 3 x 3 행렬을 만들었습니다.\n",
            "[[1.       0.224325 0.      ]\n",
            " [0.224325 1.       0.      ]\n",
            " [0.       0.       1.      ]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "doc = ['I like machine learning', 'I love deep learning', 'I run everyday']\n",
        "tfidf_vectorizer = TfidfVectorizer(min_df=1)\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(doc)\n",
        "doc_distance = (tfidf_matrix * tfidf_matrix.T)\n",
        "print('유사도를 위한', str(doc_distance.get_shape()[0]), 'x', str(doc_distance.get_shape()[1]), '행렬을 만들었습니다.')\n",
        "print(doc_distance.toarray())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RntYOCZv5Kkx"
      },
      "source": [
        "## 10.1.3 Prediction based Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Popi2GGj6D3c"
      },
      "source": [
        "### Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3H_6zHpI6ptE",
        "outputId": "729c251d-3c95-416e-eda7-53babeaf619f"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYP2atDO5hj4",
        "outputId": "e6ad7036-1d9b-4ac9-f083-5f7f3a7e8e7c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['once',\n",
              " 'upon',\n",
              " 'a',\n",
              " 'time',\n",
              " 'in',\n",
              " 'london',\n",
              " ',',\n",
              " 'the',\n",
              " 'darlings',\n",
              " 'went',\n",
              " 'out',\n",
              " 'to',\n",
              " 'a',\n",
              " 'dinner',\n",
              " 'party',\n",
              " 'leaving',\n",
              " 'their',\n",
              " 'three',\n",
              " 'children',\n",
              " 'wendy',\n",
              " ',',\n",
              " 'jhon',\n",
              " ',',\n",
              " 'and',\n",
              " 'michael',\n",
              " 'at',\n",
              " 'home',\n",
              " '.']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "sample = open('/content/peter.txt', \"r\", encoding='UTF8')\n",
        "s = sample.read()\n",
        "\n",
        "f = s.replace('\\n', ' ')\n",
        "data = []\n",
        "\n",
        "for i in sent_tokenize(f):\n",
        "  temp = []\n",
        "  for j in word_tokenize(i):\n",
        "    temp.append(j.lower())\n",
        "  data.append(temp)\n",
        "\n",
        "data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGU4CHIZ632u",
        "outputId": "133b4f43-e8f2-434d-bf25-12efdeb13c62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cosine similarity between 'peter' 'wendy' - CBOW :  -0.059717968\n"
          ]
        }
      ],
      "source": [
        "model1 = gensim.models.Word2Vec(data, min_count=1, size=100, window=5, sg=0)\n",
        "print(\"Cosine similarity between 'peter' \" + \"'wendy' - CBOW : \", model1.similarity('peter', 'wendy'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZ0OhV027qfF",
        "outputId": "9d14a87e-78df-42e2-e165-e6707134eb16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cosine similarity between 'peter' 'hook' - CBOW :  0.17057094\n"
          ]
        }
      ],
      "source": [
        "print(\"Cosine similarity between 'peter' \" + \"'hook' - CBOW : \", model1.similarity('peter', 'hook'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBhlh6GA8va3",
        "outputId": "2a27c1c9-64d1-4831-bc1a-af8529341980"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cosine similarity between 'peter' 'wendy' - Skip Gram :  0.23208164\n"
          ]
        }
      ],
      "source": [
        "model2 = gensim.models.Word2Vec(data, min_count=1, size=100, window=5, sg=1)\n",
        "print(\"Cosine similarity between 'peter' \" + \"'wendy' - Skip Gram : \", model2.similarity('peter', 'wendy'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UV39C4XE9HGh",
        "outputId": "5890ccc8-0f40-4525-f6b9-33c3e81678d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cosine similarity between 'peter' 'hook' - Skip Gram :  0.5484486\n"
          ]
        }
      ],
      "source": [
        "print(\"Cosine similarity between 'peter' \" + \"'hook' - Skip Gram : \", model2.similarity('peter', 'hook'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Iienpdan9SrG"
      },
      "outputs": [],
      "source": [
        "from gensim.test.utils import common_texts\n",
        "from gensim.models import FastText\n",
        "\n",
        "model = FastText(data, size=4, window=3, min_count=1, iter=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFo_T9gB93oe",
        "outputId": "d6e60d9e-a1a2-4577-fb30-78623037e5fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.6989395\n"
          ]
        }
      ],
      "source": [
        "sim_score = model.wv.similarity('peter', 'wendy')\n",
        "print(sim_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xknByRJc-AwC",
        "outputId": "6e4147c3-5cc4-4f14-9dee-222a611e9020"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.23571663\n"
          ]
        }
      ],
      "source": [
        "sim_score = model.wv.similarity('peter', 'hook')\n",
        "print(sim_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "k7iHomsV_bO5"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "model_kr = KeyedVectors.load_word2vec_format('data/chap10/wiki.ko.vec')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "anGfbGKa_1sq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word: 노력함, Similarity: 0.80\n",
            "Word: 노력중, Similarity: 0.75\n",
            "Word: 노력만, Similarity: 0.72\n",
            "Word: 노력과, Similarity: 0.71\n",
            "Word: 노력의, Similarity: 0.69\n",
            "Word: 노력가, Similarity: 0.69\n",
            "Word: 노력이나, Similarity: 0.69\n",
            "Word: 노력없이, Similarity: 0.68\n",
            "Word: 노력맨, Similarity: 0.68\n",
            "Word: 노력보다는, Similarity: 0.68\n"
          ]
        }
      ],
      "source": [
        "find_similar_to = '노력'\n",
        "\n",
        "for similar_word in model_kr.similar_by_word(find_similar_to):\n",
        "  print(\"Word: {0}, Similarity: {1:.2f}\".format(\n",
        "      similar_word[0], similar_word[1]\n",
        "  ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jS4Z7ybSAFYV"
      },
      "outputs": [],
      "source": [
        "similarities = model_kr.wv.most_similar(positive=['동물', '육식동물'], negative=['사람'])\n",
        "print(similarities)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3zTGBgWDac1"
      },
      "source": [
        "## 10.1.4 Counting/Prediction based Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-CYZwznDezV"
      },
      "outputs": [],
      "source": [
        "# GloVe: Global Vectors for Word Representation\n",
        "\n",
        "# LSA : Latent Semantic Analysis\n",
        "# Word2Vec\n",
        "# 두 Models의 단점을 보완"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "id": "m7sU0ol-EMKy",
        "outputId": "75f96599-b359-40a4-9eb2-c23c945966fb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/lt/7j3txvvn1bgc84pp3c9kldcw0000gn/T/ipykernel_3343/2418356103.py:12: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
            "  glove2word2vec(glove_file, word2vec_glove_file)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(400000, 100)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "%matplotlib notebook\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "from sklearn.decomposition import PCA\n",
        "from gensim.test.utils import datapath, get_tmpfile\n",
        "from gensim.models import KeyedVectors\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "\n",
        "glove_file = datapath('/Users/mini/TensorFlow/data/chap10/glove.6B.100d.txt')\n",
        "word2vec_glove_file = get_tmpfile(\"/Users/mini/TensorFlow/data/chap10/glove.6B.100d.txt\")\n",
        "glove2word2vec(glove_file, word2vec_glove_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "jcXRpUhXE1lt"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('legislation', 0.8072139620780945),\n",
              " ('proposal', 0.7306863069534302),\n",
              " ('senate', 0.7142540812492371),\n",
              " ('bills', 0.704440176486969),\n",
              " ('measure', 0.6958035230636597),\n",
              " ('passed', 0.6906244158744812),\n",
              " ('amendment', 0.6846879720687866),\n",
              " ('provision', 0.6845566630363464),\n",
              " ('plan', 0.6816462874412537),\n",
              " ('clinton', 0.6663140058517456)]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = KeyedVectors.load_word2vec_format(word2vec_glove_file)\n",
        "model.most_similar('bill')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "KJESsjBYFdaf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('peach', 0.688809871673584),\n",
              " ('mango', 0.6838189959526062),\n",
              " ('plum', 0.6684104204177856),\n",
              " ('berry', 0.659035861492157),\n",
              " ('grove', 0.6581552028656006),\n",
              " ('blossom', 0.6503506302833557),\n",
              " ('raspberry', 0.6477391123771667),\n",
              " ('strawberry', 0.6442098021507263),\n",
              " ('pine', 0.6390928626060486),\n",
              " ('almond', 0.6379212141036987)]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.most_similar('cherry')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "zJjYhOgbFf-k"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('kazushige', 0.4834350347518921),\n",
              " ('askerov', 0.4778185784816742),\n",
              " ('lakpa', 0.46915262937545776),\n",
              " ('ex-gay', 0.45713332295417786),\n",
              " ('tadayoshi', 0.4522107243537903),\n",
              " ('turani', 0.44810065627098083),\n",
              " ('saglam', 0.4469599425792694),\n",
              " ('aijun', 0.4435270130634308),\n",
              " ('adjustors', 0.44235295057296753),\n",
              " ('nyum', 0.4423117935657501)]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.most_similar(negative=['cherry'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "1DOiUqm8FkAX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "queen: 0.7699\n"
          ]
        }
      ],
      "source": [
        "result = model.most_similar(positive=['woman', 'king'], negative=['man'])\n",
        "print(\"{}: {:.4f}\".format(*result[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Lp9kQ8a7Ft-s"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'champagne'"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def analogy(x1, x2, y1):\n",
        "  result = model.most_similar(positive=[y1, x2], negative=[x1])\n",
        "  return result[0][0]\n",
        "\n",
        "analogy('australia', 'beer', 'france')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "emyGPwCsF7TQ"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'longest'"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "analogy('tall', 'tallest', 'long')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "XIdSMZ-_F98k"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cereal\n"
          ]
        }
      ],
      "source": [
        "print(model.doesnt_match('breakfast cereal dinner lunch'.split()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 10.2 Transformer Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10.2.1 seq2seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 라이브러리 호출\n",
        "\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import io\n",
        "import re\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 데이터셋 전처리 함수 정의\n",
        "\n",
        "import unicodedata\n",
        "\n",
        "def unicode_to_ascii(s):\n",
        "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "def preprocess_sentence(w):\n",
        "    w = unicode_to_ascii(w.lower().strip())\n",
        "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "    w = re.sub(r'[\" \"]+', \" \", w)\n",
        "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "    w = w.rstrip().strip()\n",
        "    w = '<start> ' + w + ' <end>'\n",
        "    return w"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<start> may i borrow this book ? <end>\n",
            "b'<start> \\xc2\\xbf puedo tomar prestado este libro ? <end>'\n"
          ]
        }
      ],
      "source": [
        "# 데이터 전처리 확인\n",
        "\n",
        "en_sentence = u\"May I borrow this book?\"\n",
        "sp_sentence = u\" ¿ Puedo tomar prestado este libro?\"\n",
        "print(preprocess_sentence(en_sentence))\n",
        "print(preprocess_sentence(sp_sentence).encode('utf-8'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# [ENGLISH, SPANISH] 형식의 단어 변환\n",
        "\n",
        "def create_dataset(path, num_examples):\n",
        "    lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
        "\n",
        "    word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')] for l in lines[:num_examples]]\n",
        "\n",
        "    return zip(*word_pairs)\n",
        "\n",
        "\n",
        "def max_length(tensor):\n",
        "    return max(len(t) for t in tensor)\n",
        "\n",
        "def tokenize(lang):\n",
        "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "    lang_tokenizer.fit_on_texts(lang)\n",
        "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
        "\n",
        "    return tensor, lang_tokenizer\n",
        "\n",
        "def load_dataset(path, num_examples=None):\n",
        "    targ_lang, inp_lang = create_dataset(path, num_examples)\n",
        "\n",
        "    input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
        "    target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
        "\n",
        "    return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 데이터셋 크기 조정\n",
        "\n",
        "num_examples = 30000\n",
        "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset('data/chap10/spa.txt', num_examples)\n",
        "\n",
        "max_length_targ, max_length_inp = max_length(target_tensor), max_length(input_tensor)\n",
        "\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metal device set to: Apple M1\n",
            "\n",
            "systemMemory: 16.00 GB\n",
            "maxCacheSize: 5.33 GB\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-19 10:49:49.928911: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
            "2022-05-19 10:49:49.929259: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
          ]
        }
      ],
      "source": [
        "# 하이퍼 파라미터 초기환\n",
        "\n",
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "steps_per_epoch = len(input_tensor_train) // BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(inp_lang.word_index) + 1\n",
        "vocab_tar_size = len(targ_lang.word_index) + 1\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 인코더 네트워크 구축\n",
        "\n",
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.enc_units = enc_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = tf.keras.layers.GRU(self.enc_units, return_sequences=True, return_state=True, recurrent_initializer='glorot_uniform')\n",
        "\n",
        "    def call(self, x, hidden):\n",
        "        x = self.embedding(x)\n",
        "        output, state = self.gru(x, initial_state=hidden)\n",
        "        return output, state\n",
        "    \n",
        "    def initialize_hidden_state(self):\n",
        "        return tf.zeros((self.batch_sz, self.enc_units))\n",
        "\n",
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 어텐션 구축\n",
        "\n",
        "class EDAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, units):\n",
        "        super(EDAttention, self).__init__()\n",
        "        self.W1 = tf.keras.layers.Dense(units)\n",
        "        self.W2 = tf.keras.layers.Dense(units)\n",
        "        self.V = tf.keras.layers.Dense(1)\n",
        "    \n",
        "    def call(self, query, values):\n",
        "        hidden_with_time_axis = tf.expand_dims(query, 1)\n",
        "        score = self.V(tf.nn.tanh(self.W1(values) + self.W2(hidden_with_time_axis)))\n",
        "        attention_weights = tf.nn.softmax(score, axis=1)\n",
        "        context_vector = attention_weights * values\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "        return context_vector, attention_weights\n",
        "\n",
        "attention_layer = EDAttention(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 디코더 네트워크 구축\n",
        "\n",
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.dec_units = dec_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = tf.keras.layers.GRU(self.dec_units, return_sequences=True, return_state=True, recurrent_initializer='glorot_uniform')\n",
        "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "        self.attention = EDAttention(self.dec_units)\n",
        "    \n",
        "    def call(self, x, hidden, enc_output):\n",
        "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "        x = self.embedding(x)\n",
        "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "        output, state = self.gru(x)\n",
        "        output = tf.reshape(output, (-1, output.shape[2]))\n",
        "        x = self.fc(output)\n",
        "        return x, state, attention_weights\n",
        "    \n",
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 옵티마이저 및 손실 함수 정의\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "    return tf.reduce_mean(loss_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 체크포인트 설정\n",
        "\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer, encoder=encoder, decoder=decoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 모델 훈련 함수 정의\n",
        "\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "    loss = 0\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "        dec_hidden = enc_hidden\n",
        "        dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "        for t in range(1, targ.shape[1]):\n",
        "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "            loss += loss_function(targ[:, t], predictions)\n",
        "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "        \n",
        "    batch_loss = (loss / int(targ.shape[1]))\n",
        "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "    return batch_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 4.6265\n",
            "Epoch 1 Batch 100 Loss 2.1590\n",
            "Epoch 1 Batch 200 Loss 1.9477\n",
            "Epoch 1 Batch 300 Loss 1.8691\n",
            "Epoch 1 Loss 2.0479\n",
            "Epoch 2 Batch 0 Loss 1.5924\n",
            "Epoch 2 Batch 100 Loss 1.5670\n",
            "Epoch 2 Batch 200 Loss 1.4960\n",
            "Epoch 2 Batch 300 Loss 1.3117\n",
            "Epoch 2 Loss 1.4602\n",
            "Epoch 3 Batch 0 Loss 1.2277\n",
            "Epoch 3 Batch 100 Loss 1.2599\n",
            "Epoch 3 Batch 200 Loss 1.0851\n",
            "Epoch 3 Batch 300 Loss 1.0105\n",
            "Epoch 3 Loss 1.1030\n",
            "Epoch 4 Batch 0 Loss 0.7619\n",
            "Epoch 4 Batch 100 Loss 0.8217\n",
            "Epoch 4 Batch 200 Loss 0.8738\n",
            "Epoch 4 Batch 300 Loss 0.7423\n",
            "Epoch 4 Loss 0.8219\n",
            "Epoch 5 Batch 0 Loss 0.6497\n",
            "Epoch 5 Batch 100 Loss 0.6700\n",
            "Epoch 5 Batch 200 Loss 0.4766\n",
            "Epoch 5 Batch 300 Loss 0.7064\n",
            "Epoch 5 Loss 0.6170\n",
            "Epoch 6 Batch 0 Loss 0.3987\n",
            "Epoch 6 Batch 100 Loss 0.4068\n",
            "Epoch 6 Batch 200 Loss 0.5498\n",
            "Epoch 6 Batch 300 Loss 0.4898\n",
            "Epoch 6 Loss 0.4590\n",
            "Epoch 7 Batch 0 Loss 0.3269\n",
            "Epoch 7 Batch 100 Loss 0.3124\n",
            "Epoch 7 Batch 200 Loss 0.3395\n",
            "Epoch 7 Batch 300 Loss 0.3778\n",
            "Epoch 7 Loss 0.3392\n",
            "Epoch 8 Batch 0 Loss 0.2104\n",
            "Epoch 8 Batch 100 Loss 0.3045\n",
            "Epoch 8 Batch 200 Loss 0.2990\n",
            "Epoch 8 Batch 300 Loss 0.2241\n",
            "Epoch 8 Loss 0.2529\n",
            "Epoch 9 Batch 0 Loss 0.1618\n",
            "Epoch 9 Batch 100 Loss 0.1273\n",
            "Epoch 9 Batch 200 Loss 0.1653\n",
            "Epoch 9 Batch 300 Loss 0.1988\n",
            "Epoch 9 Loss 0.1913\n",
            "Epoch 10 Batch 0 Loss 0.1393\n",
            "Epoch 10 Batch 100 Loss 0.1439\n",
            "Epoch 10 Batch 200 Loss 0.1340\n",
            "Epoch 10 Batch 300 Loss 0.1741\n",
            "Epoch 10 Loss 0.1483\n",
            "Time taken for 1 epoch 135.57634782791138 sec\n",
            "\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "\n",
        "    enc_hidden = encoder.initialize_hidden_state()\n",
        "    total_loss = 0\n",
        "\n",
        "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "        batch_loss = train_step(inp, targ, enc_hidden)\n",
        "        total_loss += batch_loss\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch+1, batch, batch_loss.numpy()))\n",
        "    \n",
        "    if (epoch+1) % 2 == 0:\n",
        "        checkpoint.save(file_prefix=checkpoint_prefix)\n",
        "    \n",
        "    print('Epoch {} Loss {:.4f}'.format(epoch+1, total_loss/steps_per_epoch))\n",
        "\n",
        "print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 모델 평가 및 시각화를 위한 함수\n",
        "\n",
        "def evaluate(sentence):\n",
        "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "\n",
        "    sentence = preprocess_sentence(sentence)\n",
        "\n",
        "    inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
        "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs], maxlen=max_length_inp, padding='post')\n",
        "    inputs = tf.convert_to_tensor(inputs)\n",
        "    result = ''\n",
        "    hidden = [tf.zeros((1, units))]\n",
        "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "    dec_hidden = enc_hidden\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
        "\n",
        "    for t in range(max_length_targ):\n",
        "        predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n",
        "        attention_weights = tf.reshape(attention_weights, (-1,))\n",
        "        attention_plot[t] = attention_weights.numpy()\n",
        "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "        result += targ_lang.index_word[predicted_id] + ' '\n",
        "        if targ_lang.index_word[predicted_id] == '<end>':\n",
        "            return result, sentence, attention_plot\n",
        "        \n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\n",
        "    \n",
        "    return result, sentence, attention_plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 어텐션 가중치 시각화 함수\n",
        "\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "    fontdict = {'fontsize': 14}\n",
        "\n",
        "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: <start> esta es mi vida . <end>\n",
            "Predicted translation: this is my life . <end> \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/lt/7j3txvvn1bgc84pp3c9kldcw0000gn/T/ipykernel_17597/1061925670.py:10: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
            "/var/folders/lt/7j3txvvn1bgc84pp3c9kldcw0000gn/T/ipykernel_17597/1061925670.py:11: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmYAAAJwCAYAAAAjo60MAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAiKElEQVR4nO3debSlB1nn+99DEhIhRGSONAFsxIHxxpJBbIziFaWRdaVpJ4IBvKQXVxv64tCy+tLStChg1MbGpgkocwuY2zYiohcMXJBBbkgjMijzJASIAkkIZOK5f+xdcjipCnVOKvU++9Tns9ZZtc+7d+16zruq6nzPO1Z3BwCA5V1v6QEAAFgRZgAAQwgzAIAhhBkAwBDCDABgCGEGADCEMAMAGEKYAQAMIcwAAIYQZgAAQwizgarqm6vq3Kq6y9KzAABHjjCb6YwkpyV55MJzAABHULmJ+SxVVUk+nOTVSX44yTd291WLDgUAHBG2mM1zWpIbJXlMkiuTPGDRaQCAI0aYzXNGknO6+9IkL1l/DgAcBezKHKSqbpjkk0n+eXe/oarunuTNSU7u7s8tORsAcN2zxWyWf5Hkwu5+Q5J099uTvC/Jjy85FABskqq6YVX9VFV9/dKz7JQwm+VhSV60bdmLkjz8yI8CABvrR5M8N6vvqxvFrswhquo2ST6U5Nu6+31blv+TrM7S/Pbufu9C4wHAxqiq1ya5ZZJLu3vf0vPshDADAPaMqrpdkvcmuUeStyQ5tbvfvehQO2BX5iBVdcr6OmYHfO5IzwMAG+hhSd6wPk77T7JhVzcQZrN8KMnNty+sqpuunwMArtlPJXnh+vGLkzz0YBs9JhJms1SSA+1bPjHJl47wLACwUarqu5KcnOSc9aJXJLlBku9fbKgdOnbpAUiq6rfXDzvJr1XVpVuePiar/eRvP9JzAcCGOSPJy7v7kiTp7sur6mVZXd3g1UsOdqiE2Qx3Wf9aSb4tyeVbnrs8yflJzjrSQwHApqiq47O6TMZPbHvqRUn+rKpO3B9skzkrc4j1/u+XJXlkd1+89DwAsEmq6mZZ3V/6Rd395W3PnZ7kNd19wSLD7YAwG6KqjsnqOLK7bdJpvQDA4ePg/yG6+6okH0ly/aVnAQCWYYvZIFV1Rlb7xk/v7guXngcApquqD+XAVzS4mu7+put4nGvNwf+z/HyS2yf5u6r6eJIvbH2yu++6yFQAMNcztjw+Mcnjkrw1yZvXy+6d1dUNfuMIz7UrwmyWc772SwCA/br7H4Orqp6X5Knd/atbX1NVj09ypyM82q7YlQkA7AlVdVFW98Z8/7bld0hyfneftMxkh87B/wDAXvGFJKcdYPlpSS49wPJx7MocpKqun+TfZXUCwClJjtv6fHcfs8RcALAhfivJ71TVviRvWS+7V1Z3BHjiUkPthDCb5T8m+bEkv5bVX65fSHK7JD+e5AnLjQUA83X306rqw0kem9VdAJLkPUnO6O6XLTbYDjjGbJD1Kb+P7u4/raqLk9y9uz9QVY9Ocr/ufsjCI45UVY/IV7YyftV14Dbh1GjY66rqG5L8UA78b/RJiwwFQ9liNsstk+y/6v8lSW68fvynSZ66xEDTVdUvJHl8kmcluW+S/5LkDuvH7i8KC6uqeyV5ZZLLktw8yd8lOXn9+YeTCDOuE1V142w7lr67/2GZaQ6dg/9n+WiSb1w/fn+S+68f3zvJFxeZaL5HJTmzux+f5Iokz+juB2V1vZrbLjoZkCS/nuTFSW6d1W3nvi+rLWfnxQ+cHGZVdduqelVVfTHJ3yf5zPrjwvWv49liNssfJrlfVgcsPj3J71fVo7L6D+3XlxxssH+S1YUEk1W87j8V+vfXyx+1xFDAP7prkp/u7q6qq5Ic390frKp/m+S/ZRVtcLg8N6u9TT+d5BM5xDsCTCLMBllv9dn/+Jyq+liS+yR5b3f/8XKTjXZBkptltbXxI1ltXXx7VrszN+4fJOxBl295/KmstmS/J6vDNb7xgL8Ddu8eSe7V3e9cepDdEmaDVNV9k7ypu69Mku7+yyR/WVXHVtV9u/v1y0440rlJHpTk/CS/m+S3qupHk5yaZCPOwIE97vwk35nkvUlel+RXquqWSU5P8o4F52Jv+lCS45ce4tpwVuYg6838J3f3p7ctv2mST7uO2dVV1fWSXG9/zFbVj2W9lTHJs7r7iiXng6Pd+npSN+ru11bVzZO8IF/5N/qI7v7rRQdkT6mq70vyS0n+j+1X/98UwmyQqvpyklt292e2Lb9jkvM24VYSR1pVnZLkY73tL3JVVZLbdPdHl5kMgCNtfamp45Mck9WZv1dufX4Tvo/alTlAVf3R+mEneVFVXbbl6WOS3DnJm474YJvhQ1mdev/pbctvsn7OVkaAo8fPLj3AtSXMZvj79a+V5LP56ktjXJ7kL5I8+0gPtSEqBz7I/8SsTs0HjrD1xbIPaXeMi0BzOHX385ee4doSZgN09yOSZH0bibO6+wvLTjRfVf32+mEn+bWq2npz2mOyOjPn7Ud6LiBJ8owtj09M8risLl/z5vWye2f1b/Q3jvBcHAXWJ5c8LMk/TfKE7r6wqu6T5BPd/aFlp/vaHGM2yPpA9nT3l9ef3yrJA5O8u7vtytyiql67fvg9Wf1nv/WU/MuzuqL4Wd39viM8GrBFVT0vq0v+/Oq25Y9PcqfuPn2RwdiTquo7kvx5Voey3CnJt66vm/fEJHfs7p9ccr5DIcwGqapXJfnT7n56VZ2Y5G+S3DCrnzh/urtfsOiAA1XVc5M8trsvWnoW4Oqq6qIkp24/Q66q7pDk/E04GJvNsf6h/fXd/cvrEwHutg6zeyd5SXePvyOMXZmz7Evyi+vHD05yUZLbJ3lokp/P6jRztti/G3i/qvq6rE7Ff193f2SZqTaP9XZwVfXgJK/o7ivWjw+qu//7ERprk3whyWlZ3WZuq9OSXLr9xXAtfUdWV/3f7pNZ3Y96PGE2y4lJPrd+/ANJ/nD9zeDcJL+z2FSDrXeTvLW7/0tVXT+r41julOTyqvqR7n7VogMOZb3tyDlJbpXVmb/nXMPrOs4CPpDfSvI76+uZvWW97F5JzkjyxKWGYs/6YpJvOMDyb83Vz94fyU3MZ/lokvtU1Q2zuoH5q9fLbxI/WR7M/fOV/+wflORGWX0TfWL8p39NrLdD1N3X23/R5/Xjg32IsgPo7qdldSD2XZL85vrjLknO6G43Medwe3mSX66q/Vf/76q6XZKnJvm/F5tqBxxjNkhV/auszma6JKv7Pp7a3V+uqsck+d+6+/sWHXCgqvpSkjt098er6jlJPt/dP7f+h/jX3X2jZSecyXrbvfUZX/dJcot89Q+33d3PXGYqIEmq6qQkf5Lkrlkdo31BVrsw35Tkhzbhqgd2ZQ7S3c+qqvOSnJLk1fvPzkzygSRPWG6y0S5Icueq+mRWW4HOXC8/MYnbMR2c9bYLVXV6kufkK9cc3PqTbScRZrCg9Ylg372+NdOpWf3wdH53v2bZyQ6dMBuiqr4+yV27+w1J3rbt6c8lefcRH2oz/F6Slyb5RJKrsjpNOknumdVZrRyY9bY7T07ytCRP2n9/Vq5ufSbmN62vH3VxruFis87K5HDZ+n20u89Ncu6W5+6T1aWnPrvYgIdImM3x5SSvqqr7d/cb9y+sqrtl9Zfr1otNNlh3P6mq3pnktkle1t37r2d2ZVbHFHAA1tuunZTkeaLsa/rXSS5eP974W+SwMfbE91EH/w/R3RdnddDiT2176mFJ/qy7LzzyU22MLyb5/iSvrqrbrJddP6tj9Tg4623nXpzkny89xHTd/fzu3n/P3x/J6u/U76+Xf9XHgmOyx+yV76PCbJYXJPmX68sX7L8TwE8med6SQ01WVQ9N8rIk783qmm/HrZ+6Xr5yTTi2sd527XFJfqiq/kdV/ceq+vdbP5YebqhLkzw/yaeq6jlV9T1LD8SetvHfR4XZLK/OaivGA9ef3y+rLRivWGyi+X4xyaO6+//Majfcfm9JcvdFJtoM1tvu/KskP5jku7LaEvQvt3w8ZMG5xlrfAueWWe3e/MasttB+pKqeUlV3XnY69qCN/z4qzAZZn4X5onxlM+zDkry0u50ld3DfnK/cGHmrS7I6HogDs9525wlJfq67b9Hdd+7uu2z5uOvSw03V3V/o7hd19wOyOs7n17P6xvn2RQdjz9kL30cd/D/PC5K8rapOyeon8vstPM90n0hyx6yu+7bVfbO6zAgHZr3tzjFJ/mjpITZVVZ2Q5PuyukTLHZN8bNmJ2KM2+vuoLWbDdPe7krwzq4OMP97db114pOnOTvLb61Ohk+Q2VXVGVpc0cE2pg7Pedue5Wd27lkNUKz9QVc9P8qms/n59Isn9uvv2y07HXrTp30dtMZvpBUn+U5J/t/Ac43X309bXrnl1khOSvDbJZUnO6m73Fz0I623XbpDkf6+q+yd5R7ZdjLe7H7PIVLN9Mqvd469K8vAkr9xyeRZ2oarek+Sbu9v38IPb2O+jbsk0UFXdJKsDZZ/V3RcsPc8mqKobJPn2rLYCv7u7XfLhEFhvO1NVr72Gp9tt066uqh6V5A+6+3NLz7JXVNXPJrlpd/+HpWeZapO/jwozAIAhHGMGADCEMAMAGEKYDVZVZy49wyay3nbOOtsd6213rLeds852ZxPXmzCbbeP+Qg1hve2cdbY71tvuWG87Z53tzsatN2EGADDEUX9W5vXr+D4hN1x6jAO6IpfluBy/9Bgbx3rbOetsd6y33bHeds46253J6+3ifPbC7r759uVH/cXpTsgNc8/aqLs1wNGlaukJNtNR/kM3TPeaPmf7LfGS2JUJADCGMAMAGEKYAQAMIcwAAIYQZgAAQwgzAIAhhBkAwBDCDABgCGEGADCEMAMAGEKYAQAMIcwAAIYQZgAAQwgzAIAhhBkAwBDCDABgCGEGADCEMAMAGEKYAQAMIcwAAIYQZgAAQwgzAIAhhBkAwBDCDABgCGEGADCEMAMAGEKYAQAMIcwAAIYQZgAAQwgzAIAhhBkAwBDCDABgiJFhVlWnVVVX1c2uzWsAADbJiDCrqtdV1TN2+NvelOTkJH9/HYwEAHDEHbv0ALvV3ZcnuWDpOQAADpfFt5hV1fOSfE+Sn1nvmuwkt1s/fbeq+suqurSqzquqU7f8vq/alVlVX19VL6yqT1fVl6rqg1X1b47wlwMAsGuLh1mSxyZ5c5LnZrVr8uQkH1s/92tJfinJqVntsnxxVdVB3udXktwlyQOTfEuSRyb5u+tubACAw2vxXZnd/fmqujzJpd19QZJU1beun35Cd792vexJSf4iya2TfPwAb3XbJOd391vXn3/kYH9mVZ2Z5MwkOSE3OCxfBwDAtTVhi9k1eceWx59Y/3qLg7z2mUl+rKr+qqrOqqrvOdibdvfZ3b2vu/cdl+MP16wAANfK9DC7YsvjXv96wJm7+1VZbTU7K8nNkryyqp573Y4HAHD4TAmzy5Mcc23fpLsv7O4XdvfDk/x0kjOqyiYxAGAjLH6M2dqHk9yjqm6X5JLsIhjXx6Cdn+RdWX1dD07ywe6+7PCNCQBw3ZmyxeysrLaavTvJZ5Kcsov3uCzJk5P8VZI3JrlRkh8+XAMCAFzXqru/9qv2sJPqJn3Put/SYwAHc9Ar5HCNjvL/22G61/Q5b+vufduXT9liBgBw1BNmAABDCDMAgCGEGQDAEMIMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhhBmAABDCDMAgCGEGQDAEMIMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhhBmAABDCDMAgCGEGQDAEMIMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhhBmAABDCDMAgCGEGQDAEMIMAGAIYQYAMIQwAwAY4tilB1haHXdcjr3VrZceY+P01x2/9Agb50df8RdLj7CRfvvp/2LpETbSLd/42aVH2Dj10U8uPcJGuurzFy09wmbqAy+2xQwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYIiNDrOqel5V/fHScwAAHA7HLj3AtfTYJLX0EAAAh8NGh1l3f37pGQAADpc9syuzqu5bVW+pqkuq6vNV9daquvPSMwIAHKqN3mK2X1Udm+TlSX43yUOTHJfk1CRXLTkXAMBO7IkwS3JSkhsneUV3f2C97G8O9uKqOjPJmUlywjE3us6HAwA4FBu9K3O/7v6HJM9L8mdV9cqqelxVnXINrz+7u/d1977rX+/rjticAADXZE+EWZJ09yOS3DPJ65M8KMnfVtX9l50KAODQ7ZkwS5Lu/qvufmp3n5bkdUnOWHYiAIBDtyfCrKpuX1VPqarvqqrbVtX3JrlrkncvPRsAwKHaKwf/X5rkjkn+IMnNknwqyYuTPHXJoQAAdmKjw6y7H77l0wcvNQcAwOGwJ3ZlAgDsBcIMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhhBmAABDCDMAgCGEGQDAEMIMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhhBmAABDCDMAgCGEGQDAEMIMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhhBmAABDCDMAgCGEGQDAEMIMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhhBmAABDHLv0AEvrK67IlR//u6XH4Cjwkof+r0uPsJHOf8Uzlx5hI33n//XopUfYON9w4vFLj7CRjvmr9y89wma65MCLbTEDABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIcaFWVW9rqqeWVW/UVX/UFWfqarHVtXxVfU7VfW5qvpoVT1s/fpzq+oZ297jpKq6tKoevMxXAQCwc+PCbO2hSS5Ocs8kT0nyn5L8jyTvTbIvyfOTPKeqTk7y7CQ/WVXHb/n9P5HkkiSvOHIjAwBcO1PD7F3d/cTufl+S30xyYZIruvvp3f3+JE9KUknuk+S/J/lykh/Z8vsfmeQF3X3Fgd68qs6sqvOq6rwrctl1+oUAAByqqWH2jv0PuruTfDrJX29ZdkWSzya5RXdfluSFWcVYqupOSe6R5HcP9ubdfXZ37+vufcfl+IO9DADgiDp26QEOYvuWrj7Isv1h+Zwk76iqU7IKtDd393uu2xEBAA6vqVvMdqS735XkL5M8KsnpSX5v2YkAAHZu6haz3Xh2kv+a1Za1ly48CwDAju2JLWZrL01yeZKXdffFSw8DALBT47aYdfdpB1h25wMsu9W2RTdO8nW5hoP+AQAmGxdmO1VVxyW5aZJfTfI/u/uNC48EALAre2FX5n2SfDLJd2V18D8AwEba+C1m3f26rC42CwCw0fbCFjMAgD1BmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMcu/QAcLTot71r6RE20g+esm/pETbSSz7w60uPsHEe+NZHLz3CRrr942+x9Aib6X0HXmyLGQDAEMIMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhhBmAABDCDMAgCGEGQDAEMIMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhhBmAABDCDMAgCGEGQDAEMIMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhhBmAABDCDMAgCGEGQDAEMIMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhhBmAABDCDMAgCGEGQDAEMIMAGCIkWFWVc+rqj/e/nj9+fWq6llV9fdV1VV12lJzAgAcTscuPcAheGyS2vL5A5I8IslpST6Y5B8WmAkA4LAbH2bd/flti+6Q5JPd/aYl5gEAuK6M3JW51fbdmkl+K8kp692YH14vr6r6xar6QFV9sar+uqpOX25qAICdG7/FbJvHJvlIkkcm+c4kV62X/0qShyT5mSR/m+TeSZ5dVZ/t7lcuMSgAwE5tVJh19+er6uIkV3X3BUlSVTdM8rgkP9Ddb1i/9ENVdY+sQu1qYVZVZyY5M0lOyA2OyOwAAF/LRoXZQXx7khOS/GlV9ZblxyX58IF+Q3efneTsJDmpbtIHeg0AwJG2F8Js/3FyP5zko9ueu+IIzwIAsGt7IczeneSyJLft7nOXHgYAYLc2Psy6++KqOivJWVVVSV6f5MQk90ry5fVuSwCA8TY+zNaekORTSX4+yTOTXJTk7UmetuBMAAA7MjLMuvvhB3q8/vysJGdtW9ZJ/vP6AwBgI42/wCwAwNFCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYIhjlx4A4Jr0lVcuPcJGesx3//jSI2ych//JW5YeYSO9/8W3WHqEzXSPAy+2xQwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMcu/QAS6iqM5OcmSQn5AYLTwMAsHJUbjHr7rO7e1937zsuxy89DgBAkqM0zAAAJhJmAABD7Nkwq6qfraq/WXoOAIBDtWfDLMnNknzL0kMAAByqPRtm3f3E7q6l5wAAOFR7NswAADaNMAMAGEKYAQAMIcwAAIYQZgAAQwgzAIAhhBkAwBDCDABgCGEGADCEMAMAGEKYAQAMIcwAAIYQZgAAQwgzAIAhhBkAwBDCDABgCGEGADCEMAMAGEKYAQAMIcwAAIYQZgAAQwgzAIAhhBkAwBDCDABgCGEGADCEMAMAGEKYAQAMIcwAAIYQZgAAQwgzAIAhhBkAwBDHLj0AAIfflR/7+NIjbJxz73LDpUfYSB96yl2XHmFPscUMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhhBmAABDCDMAgCGEGQDAEMIMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhhBmAABDCDMAgCGEGQDAEMIMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhhBmAABDCDMAgCGEGQDAEMIMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhhBmAABDCDMAgCGEGQDAEMIMAGAIYQYAMMTGhFlV/XxVfXjpOQAArisbE2YAAHvdYQmzqjqpqm58ON5rB3/mzavqhCP5ZwIAXJd2HWZVdUxV3b+q/luSC5Lcbb3866vq7Kr6dFVdXFX/b1Xt2/L7Hl5Vl1TV/arqnVX1hap6bVXdftv7/2JVXbB+7QuSnLhthAckuWD9Z91nt18HAMAUOw6zqrpTVT0tyceSvDTJF5L8YJLXV1UleWWSWyd5YJL/Jcnrk5xbVSdveZvjkzw+ySOT3DvJjZP81y1/xo8m+ZUkv5zk1CR/m+Rx20Z5cZKfTHKjJK+uqvdX1b/fHngAAJvikMKsqm5aVY+pqrcl+Z9JvjXJY5Pcqrsf1d2v7+5O8r1J7p7kId391u5+f3c/IckHkzxsy1sem+Rn1q95R5Kzkpy2Drsk+TdJnt/dz+ru93b3k5O8detM3X1ld/9Jd/9Eklsl+dX1n/++qnpdVT2yqrZvZdv/9ZxZVedV1XlX5LJDWQUAANe5Q91i9q+TPD3Jl5Lcsbsf1N1/0N1f2va670hygySfWe+CvKSqLkly5yT/dMvrLuvuv93y+SeSXD/JN6w//7Ykb9723ts//0fdfVF3/153f2+S70xyyyS/m+QhB3n92d29r7v3HZfjr+HLBgA4co49xNedneSKJD+V5J1V9YdJXpjkz7v7qi2vu16STyX5Zwd4j4u2PL5y23O95ffvWFUdn9Wu09OzOvbsXVltdXv5bt4PAGAJhxRC3f2J7n5yd39Lku9PckmSlyT5eFX9RlXdff3S87PaWvXl9W7MrR+f3sFc70lyr23LvurzWvnuqnpWVicf/Ock70/yHd19anc/vbs/u4M/EwBgUTveQtXdb+nuRyc5OatdnHdM8v9V1T9L8pokb0zy8qr6oaq6fVXdu6r+w/r5Q/X0JGdU1aOq6pur6vFJ7rntNacn+X+SnJTkJ5Lcprt/obvfudOvCQBggkPdlXk13X1ZknOSnFNVt0hyVXd3VT0gqzMqn53kFlnt2nxjkhfs4L1fWlXflOTJWR2z9kdJfjPJw7e87M+zOvngoqu/AwDA5qnVyZRHr5PqJn3Put/SYwDARvrQU+699Agb6QP/9ufe1t37ti93SyYAgCGEGQDAEMIMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhhBmAABDCDMAgCGEGQDAEMIMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhhBmAABDCDMAgCGEGQDAEMIMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhhBmAABDCDMAgCGEGQDAEMIMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhjh26QEAgM11+19689IjbKQPHGS5LWYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABji2KUHWEJVnZnkzCQ5ITdYeBoAgJWjcotZd5/d3fu6e99xOX7pcQAAkhylYQYAMJEwAwAYQpgBAAwhzAAAhhBmAABDCDMAgCGEGQDAEMIMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhhBmAABDCDMAgCGEGQDAEMIMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhhBmAABDCDMAgCGEGQDAEMIMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhhBmAABDCDMAgCGEGQDAEMIMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhhBmAABDVHcvPcOiquozST6y9BwHcbMkFy49xAay3nbOOtsd6213rLeds852Z/J6u21333z7wqM+zCarqvO6e9/Sc2wa623nrLPdsd52x3rbOetsdzZxvdmVCQAwhDADABhCmM129tIDbCjrbeess92x3nbHets562x3Nm69OcYMAGAIW8wAAIYQZgAAQwgzAIAhhBkAwBDCDABgiP8ff16vSZISsosAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 번역을 위한 함수 정의 및 번역 문장 입력 함수\n",
        "\n",
        "def translate(sentence):\n",
        "    result, sentence, attention_plot = evaluate(sentence)\n",
        "\n",
        "    print('Input: %s' % sentence)\n",
        "    print('Predicted translation: {}'.format(result))\n",
        "\n",
        "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))\n",
        "\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "\n",
        "translate(u'esta es mi vida.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10.2.2 BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install bert-for-tf2\n",
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(50000, 2)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 라이브러리 호출 및 데이터셋 준비\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import layers\n",
        "import bert\n",
        "import pandas as pd\n",
        "\n",
        "movie_reviews = pd.read_csv('data/chap10/IMDB Dataset.csv')\n",
        "movie_reviews.isnull().values.any()\n",
        "movie_reviews.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['review' 'sentiment']\n"
          ]
        }
      ],
      "source": [
        "# 데이터셋 전처리\n",
        "\n",
        "def preprocess_text(sen):\n",
        "    sentence = remove_tags(sen)\n",
        "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
        "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s\", ' ', sentence)\n",
        "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
        "    return sentence\n",
        "\n",
        "TAG_RE = re.compile(r'<[^>]+>')\n",
        "def remove_tags(text):\n",
        "    return TAG_RE.sub('', text)\n",
        "\n",
        "reviews = []\n",
        "sentences = list(movie_reviews['review'])\n",
        "for sen in sentences:\n",
        "    reviews.append(preprocess_text(sen))\n",
        "\n",
        "print(movie_reviews.columns.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['positive', 'negative'], dtype=object)"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# sentiment 열에 대한 고유값 확인\n",
        "\n",
        "movie_reviews.sentiment.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 긍정/부정 감정 변환\n",
        "\n",
        "y = movie_reviews['sentiment']\n",
        "y = np.array(list(map(lambda x: 1 if x =='positive' else 0, y)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Phil the Alien is one of those quirky films where the humour is based around the oddness of everything rather than actual punchlines At first it was very odd and pretty funny but as the movie progressed didn find the jokes or oddness funny anymore Its low budget film thats never problem in itself there were some pretty interesting characters but eventually just lost interest imagine this film would appeal to stoner who is currently partaking For something similar but better try Brother from another planet \n"
          ]
        }
      ],
      "source": [
        "# 리뷰 출력\n",
        "\n",
        "print(reviews[10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n"
          ]
        }
      ],
      "source": [
        "# 긍정/부정 리뷰 확인\n",
        "\n",
        "print(y[10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 텍스트의 토큰화\n",
        "\n",
        "BertTokenizer = bert.bert_tokenization.FullTokenizer\n",
        "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\", trainable=False)\n",
        "vocabulary_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "to_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer = BertTokenizer(vocabulary_file, to_lower_case)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['don', \"'\", 't', 'be', 'so', 'judgment', '##al']"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 임의의 문장 토큰화\n",
        "\n",
        "tokenizer.tokenize(\"don't be so judgmental\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[2123, 1005, 1056, 2022, 2061, 8689, 2389]"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 토큰의 ID 변환\n",
        "\n",
        "tokenizer.convert_tokens_to_ids(tokenizer.tokenize(\"don't be so judgmental\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 리뷰 텍스트 데이터 토큰화\n",
        "\n",
        "def tokenize_reviews(text_reviews):\n",
        "    return tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text_reviews))\n",
        "\n",
        "tokenized_reviews = [tokenize_reviews(review) for review in reviews]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-19 12:17:08.458127: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(32, 21), dtype=int32, numpy=\n",
              " array([[ 2054,  5896,  2054,  2466,  2054,  6752,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0],\n",
              "        [ 3191,  1996,  2338,  5293,  1996,  3185,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0],\n",
              "        [ 3078,  5436,  3078,  3257,  3532,  7613,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0],\n",
              "        [ 2062, 23873,  3993,  2062, 11259,  2172,  2172,  2062, 14888,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0],\n",
              "        [ 2023,  3185,  2003,  6659,  2021,  2009,  2038,  2070,  2204,\n",
              "          3896,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0],\n",
              "        [ 1045,  2876,  9278,  2023,  2028,  2130,  2006,  7922, 12635,\n",
              "          2305,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0],\n",
              "        [ 8235,  1998,  3048,  4616,  2011,  3419,  2457, 27727,  1998,\n",
              "          2848, 16133,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0],\n",
              "        [ 1045,  3246,  2023,  2177,  1997,  2143, 11153,  2196,  2128,\n",
              "         15908,  2015,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0],\n",
              "        [ 7918, 14674,  7662,  2003,  6581,  2003,  2023,  2143,  2002,\n",
              "          3084, 17160,  2450,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0],\n",
              "        [ 2023,  2003,  2307,  3185,  2205,  2919,  2009,  2003,  2025,\n",
              "          2800,  2006,  2188,  2678,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0],\n",
              "        [11861,  1996, 21442,  6895,  3238,  2515,  2210, 22759,  6198,\n",
              "          1998,  3185,  2087, 12487,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0],\n",
              "        [ 2017,  2488,  5454,  2703,  2310, 25032,  8913,  8159,  2130,\n",
              "          2065,  2017,  2031,  3427,  2009,     0,     0,     0,     0,\n",
              "             0,     0,     0],\n",
              "        [ 2053,  7615,  5236,  3185,  3772,  2779,  2030,  4788,  9000,\n",
              "          2053,  3168,  2012,  2035, 13558,  2009,     0,     0,     0,\n",
              "             0,     0,     0],\n",
              "        [ 1045,  2123,  2113,  2339,  2066,  2023,  3185,  2061,  2092,\n",
              "          2021,  2196,  2131,  5458,  1997,  3666,  2009,     0,     0,\n",
              "             0,     0,     0],\n",
              "        [ 2146, 11771,  1038,  8523,  8458,  6633,  3560,  2196,  2031,\n",
              "          2042,  2061,  5580,  2000,  2156,  4566,  6495,  4897,     0,\n",
              "             0,     0,     0],\n",
              "        [ 7615,  2023,  3185,  2003,  5263,  2003,  6659,  2200, 17727,\n",
              "          3217,  3676,  3468,  2919,  7613,  3257,  2025,  2298,     0,\n",
              "             0,     0,     0],\n",
              "        [ 2074,  2293,  1996,  6970, 13068,  2090,  2048,  2307,  3494,\n",
              "          1997,  2754,  3898,  2310,  3593,  2102,  6287,  5974,     0,\n",
              "             0,     0,     0],\n",
              "        [ 7078, 10392,  3649,  2360,  2876,  2079,  2023,  2104,  9250,\n",
              "          3185,  1996,  3425,  2009, 17210,  3422,  2009,  2085, 10392,\n",
              "             0,     0,     0],\n",
              "        [ 1037,  7244,  3185,  2009,  2003,  2440,  1997,  6699,  1998,\n",
              "          6919,  3772,  2071,  2031,  2938,  2083,  2009,  2117,  2051,\n",
              "             0,     0,     0],\n",
              "        [ 2235,  3077,  2792,  3425,  2003,  1996,  2190,  2792,  1997,\n",
              "          2235,  3077,  2009,  2026,  5440,  2792,  1997,  2235,  3077,\n",
              "             0,     0,     0],\n",
              "        [ 2023,  2003,  1996, 15764,  3185,  2544,  1997,  8429, 24905,\n",
              "         17988,  7659,  2498,  2021,  2045,  2024,  2053, 13842,  5312,\n",
              "             0,     0,     0],\n",
              "        [ 5587,  2023,  2210, 17070,  2000,  2115,  2862,  1997,  6209,\n",
              "         24945,  2009, 26354, 28394,  2102,  6057,  1998,  2203, 27242,\n",
              "             0,     0,     0],\n",
              "        [ 2235,  3077,  2792,  3425,  2003,  1996,  2190,  2792,  1997,\n",
              "          2235,  3077,  2009,  2026,  5440,  2792,  1997,  2235,  3077,\n",
              "             0,     0,     0],\n",
              "        [ 2023,  2003,  2204,  2143,  2023,  2003,  2200,  6057,  2664,\n",
              "          2044,  2023,  2143,  2045,  2020,  2053,  2204,  8471,  3152,\n",
              "             0,     0,     0],\n",
              "        [ 1037,  5790,  1997,  2515,  2025,  4088,  2000,  4671,  2129,\n",
              "         10634,  2139, 24128,  1998, 21660,  2135,  2919,  2023,  3185,\n",
              "          2003,     0,     0],\n",
              "        [ 6283,  2009,  2007,  2035,  2026,  2108,  5409,  3185,  2412,\n",
              "         10597, 21985,  2393,  2033,  2009,  2001,  2008,  2919,  3404,\n",
              "          2033,     0,     0],\n",
              "        [ 1037,  2033,  6491, 11124,  6774,  2143,  2008,  5121,  7906,\n",
              "          2115,  3086,  3841, 13196,  2003, 17160,  1998, 26103,  2000,\n",
              "          3422,     0,     0],\n",
              "        [ 2005,  5760,  7788,  4393,  8808,  2498,  2064, 12826,  2000,\n",
              "          1996, 11056,  3152,  3811, 16755,  2169,  1998,  2296,  2028,\n",
              "          1997,  2068,     0],\n",
              "        [ 7244,  2092,  2856, 10828,  1997, 10904,  2402,  2472,  3135,\n",
              "          2293,  2466,  2007, 10958,  8428, 10102,  1999,  1996,  4281,\n",
              "          4276,  3773,     0],\n",
              "        [ 2028,  1997,  1996,  4569, 15580,  2102,  5691,  2081,  1999,\n",
              "          3522,  2086,  2204, 23191,  5436,  1998, 11813,  6370,  2191,\n",
              "          2023,  2028,  4438],\n",
              "        [ 2023,  3185,  2097,  2467,  2022,  5934,  1998,  3185,  4438,\n",
              "          2004,  2146,  2004,  2045,  2024,  2145,  2111,  2040,  6170,\n",
              "          3153,  1998,  2552],\n",
              "        [ 2307,  3185,  2926,  1996,  2189,  3802,  2696,  2508,  2012,\n",
              "          2197,  2023,  8847,  6702,  2043,  2017,  2031,  2633,  2179,\n",
              "          2008,  2569,  2619]], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 0, 0, 1, 1, 1, 1, 1, 0], dtype=int32)>)"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 문장 길이 통일\n",
        "\n",
        "import random\n",
        "\n",
        "reviews_with_len = [[review, y[i], len(review)] for i, review in enumerate(tokenized_reviews)]\n",
        "random.shuffle(reviews_with_len)\n",
        "reviews_with_len.sort(key=lambda x: x[2])\n",
        "sorted_reviews_labels = [(review_lab[0], review_lab[1]) for review_lab in reviews_with_len]\n",
        "processed_dataset = tf.data.Dataset.from_generator(lambda: sorted_reviews_labels, output_types=(tf.int32, tf.int32))\n",
        "BATCH_SIZE = 32\n",
        "batched_dataset = processed_dataset.padded_batch(BATCH_SIZE, padded_shapes=((None, ), ()))\n",
        "\n",
        "next(iter(batched_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 데이터셋을 훈련과 검증 세트로 분리\n",
        "\n",
        "import math\n",
        "\n",
        "TOTAL_BATCHES = math.ceil(len(sorted_reviews_labels) / BATCH_SIZE)\n",
        "TEST_BATCHES = TOTAL_BATCHES // 10\n",
        "batched_dataset.shuffle(TOTAL_BATCHES)\n",
        "test_data = batched_dataset.take(TEST_BATCHES)\n",
        "train_data = batched_dataset.skip(TEST_BATCHES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 네트워크 생성\n",
        "\n",
        "class TEXT_MODEL(tf.keras.Model):\n",
        "    def __init__(self,\n",
        "                 vocabulary_size,\n",
        "                 embedding_dimensions=128,\n",
        "                 cnn_filters=50,\n",
        "                 dnn_units=512,\n",
        "                 model_output_classes=2,\n",
        "                 dropout_rate=0.1,\n",
        "                 training=False,\n",
        "                 name=\"text_model\"):\n",
        "        super(TEXT_MODEL, self).__init__(name=name)\n",
        "    \n",
        "        self.embedding = tf.keras.layers.Embedding(vocabulary_size, \n",
        "                                                   embedding_dimensions)\n",
        "        self.cnn_layer1 = tf.keras.layers.Conv1D(filters=cnn_filters,\n",
        "                                                 kernel_size=2,\n",
        "                                                 padding='valid',\n",
        "                                                 activation='relu')\n",
        "        self.cnn_layer2 = tf.keras.layers.Conv1D(filters=cnn_filters,\n",
        "                                                 kernel_size=3,\n",
        "                                                 padding='valid',\n",
        "                                                 activation='relu')\n",
        "        self.cnn_layer3 = tf.keras.layers.Conv1D(filters=cnn_filters,\n",
        "                                                 kernel_size=4,\n",
        "                                                 padding='valid',\n",
        "                                                 activation='relu')\n",
        "        self.pool = tf.keras.layers.GlobalMaxPool1D()\n",
        "        self.dense_1 = tf.keras.layers.Dense(units=dnn_units, activation='relu')\n",
        "        self.dropout = tf.keras.layers.Dropout(rate=dropout_rate)\n",
        "        if model_output_classes == 2:\n",
        "            self.last_dense = tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
        "        else:\n",
        "            self.last_dense = tf.keras.layers.Dense(units=model_output_classes, activation='softmax')\n",
        "        \n",
        "    def call(self, inputs, training):\n",
        "        l = self.embedding(inputs)\n",
        "        l_1 = self.cnn_layer1(l)\n",
        "        l_1 = self.pool(l_1)\n",
        "        l_2 = self.cnn_layer2(l)\n",
        "        l_2 = self.pool(l_2)\n",
        "        l_3 = self.cnn_layer3(l)\n",
        "        l_3 = self.pool(l_3)\n",
        "\n",
        "        concatenated = tf.concat([l_1, l_2, l_3], axis=-1)\n",
        "        concatenated = self.dense_1(concatenated)\n",
        "        concatenated = self.dropout(concatenated, training)\n",
        "        model_output = self.last_dense(concatenated)\n",
        "        return model_output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 하이퍼파라미터 초기화\n",
        "\n",
        "VOCAB_LENGTH = len(tokenizer.vocab)\n",
        "EMB_DIM = 200\n",
        "CNN_FILTERS = 100\n",
        "DNN_UNITS = 256\n",
        "OUTPUT_CLASSES = 2\n",
        "DROPOUT_RATE = 0.2\n",
        "NB_EPOCHS = 5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 하이퍼파라미터 값을 네트워크에 전달\n",
        "\n",
        "text_model = TEXT_MODEL(vocabulary_size=VOCAB_LENGTH,\n",
        "                        embedding_dimensions=EMB_DIM,\n",
        "                        cnn_filters=CNN_FILTERS,\n",
        "                        dnn_units=DNN_UNITS,\n",
        "                        model_output_classes=OUTPUT_CLASSES,\n",
        "                        dropout_rate=DROPOUT_RATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-19 12:45:35.147588: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1407/1407 [==============================] - 101s 70ms/step - loss: 0.3020 - accuracy: 0.8651\n",
            "Epoch 2/5\n",
            "1407/1407 [==============================] - 114s 81ms/step - loss: 0.1302 - accuracy: 0.9512\n",
            "Epoch 3/5\n",
            "1407/1407 [==============================] - 113s 80ms/step - loss: 0.0645 - accuracy: 0.9764\n",
            "Epoch 4/5\n",
            "1407/1407 [==============================] - 117s 83ms/step - loss: 0.0337 - accuracy: 0.9880\n",
            "Epoch 5/5\n",
            "1407/1407 [==============================] - 118s 84ms/step - loss: 0.0209 - accuracy: 0.9926\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x327a8d3d0>"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 모델 훈련\n",
        "\n",
        "if OUTPUT_CLASSES == 2:\n",
        "    text_model.compile(loss=\"binary_crossentropy\",\n",
        "                       optimizer=\"adam\",\n",
        "                       metrics=[\"accuracy\"])\n",
        "\n",
        "else:\n",
        "    text_model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                       optimizer=\"adam\",\n",
        "                       metrics=[\"accuracy\"])\n",
        "\n",
        "text_model.fit(train_data, epochs=NB_EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-19 12:54:57.796306: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "156/156 [==============================] - 5s 32ms/step - loss: 0.5165 - accuracy: 0.8918\n",
            "[0.516525149345398, 0.8918269276618958]\n"
          ]
        }
      ],
      "source": [
        "# 모델 성능 평가\n",
        "\n",
        "results = text_model.evaluate(test_data)\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 라이브러리 호출\n",
        "\n",
        "import pandas as pd\n",
        "import bert\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.optimizers import RMSprop, Adam\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 데이터셋 메모리로 로딩\n",
        "\n",
        "train_data = pd.read_csv('data/chap10/train.csv')\n",
        "test_data = pd.read_csv('data/chap10/test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 텍스트 토큰화\n",
        "\n",
        "url = 'https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/2'\n",
        "bert_layer = hub.KerasLayer(url, trainable=True)\n",
        "\n",
        "FullTokenizer = bert.bert_tokenization.FullTokenizer\n",
        "\n",
        "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer = FullTokenizer(vocab_file, do_lower_case)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 텍스트 전처리\n",
        "\n",
        "def bert_encoder(texts, tokenizer, max_len=512):\n",
        "    all_tokens = []\n",
        "    all_masks = []\n",
        "    all_segments = []\n",
        "\n",
        "    for text in texts:\n",
        "        text = tokenizer.tokenize(text)\n",
        "        text = text[:max_len-2]\n",
        "        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n",
        "        pad_len = max_len - len(input_sequence)\n",
        "        tokens = tokenizer.convert_tokens_to_ids(input_sequence)\n",
        "        tokens += [0] * pad_len\n",
        "        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n",
        "        segment_ids = [0] * max_len\n",
        "        all_tokens.append(tokens)\n",
        "        all_masks.append(pad_masks)\n",
        "        all_segments.append(segment_ids)\n",
        "    \n",
        "    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)\n",
        "\n",
        "train_input = bert_encoder(train_data, tokenizer, max_len=160)\n",
        "train_labels = train_data.target.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " positional_ids (InputLayer)    [(None, 160)]        0           []                               \n",
            "                                                                                                  \n",
            " input_mask (InputLayer)        [(None, 160)]        0           []                               \n",
            "                                                                                                  \n",
            " segment_ids (InputLayer)       [(None, 160)]        0           []                               \n",
            "                                                                                                  \n",
            " keras_layer_2 (KerasLayer)     [(None, 1024),       335141889   ['positional_ids[0][0]',         \n",
            "                                 (None, 160, 1024)]               'input_mask[0][0]',             \n",
            "                                                                  'segment_ids[0][0]']            \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem (Slic  (None, 1024)        0           ['keras_layer_2[0][1]']          \n",
            " ingOpLambda)                                                                                     \n",
            "                                                                                                  \n",
            " dense_21 (Dense)               (None, 1)            1025        ['tf.__operators__.getitem[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 335,142,914\n",
            "Trainable params: 335,142,913\n",
            "Non-trainable params: 1\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/homebrew/Caskroom/miniforge/base/envs/tf3.8/lib/python3.8/site-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "# 모델 생성\n",
        "\n",
        "def build_model(max_len=512):\n",
        "    input_word_ids = tf.keras.layers.Input(shape=(max_len,), dtype=tf.int32, name='positional_ids')\n",
        "    input_segment_ids = tf.keras.layers.Input(shape=(max_len,), dtype=tf.int32, name='segment_ids')\n",
        "    input_mask = tf.keras.layers.Input(shape=(max_len,), dtype=tf.int32, name='input_mask')\n",
        "    pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, input_segment_ids])\n",
        "    clf_output = sequence_output[:, 0, :]\n",
        "    output = tf.keras.layers.Dense(1, activation='sigmoid')(clf_output)\n",
        "    model = tf.keras.Model(inputs=[input_word_ids, input_mask, input_segment_ids], outputs=output)\n",
        "\n",
        "    model.compile(optimizer=RMSprop(lr=2e-6), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "model = build_model(max_len=160)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-19 13:01:11.150941: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - ETA: 0s - loss: 0.4802 - accuracy: 1.0000"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-19 13:02:02.517607: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 75s 75s/step - loss: 0.4802 - accuracy: 1.0000 - val_loss: 0.2104 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 13s 13s/step - loss: 0.1686 - accuracy: 1.0000 - val_loss: 0.1584 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 13s 13s/step - loss: 0.1502 - accuracy: 1.0000 - val_loss: 0.1166 - val_accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "# 모델 훈련\n",
        "train_history = model.fit(\n",
        "    train_input, train_labels,\n",
        "    validation_split=0.2,\n",
        "    epochs=3,\n",
        "    batch_size=8\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10.2.3 ELMo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pre-trained language model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 10.3 Korean Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 예제를 진행할 텍스트 생성\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "text = \"\"\"과일 가게에 사과가 많이 진열되어 있다\n",
        "그녀가 나에게 사과한 후, 우리는 친해졌다\n",
        "애플은 사과 모양을 로고로 사용한다\\n\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0,  0,  1,  2],\n",
              "       [ 0,  0,  0,  1,  2,  3],\n",
              "       [ 0,  0,  1,  2,  3,  4],\n",
              "       [ 0,  1,  2,  3,  4,  5],\n",
              "       [ 1,  2,  3,  4,  5,  6],\n",
              "       [ 0,  0,  0,  0,  7,  8],\n",
              "       [ 0,  0,  0,  7,  8,  9],\n",
              "       [ 0,  0,  7,  8,  9, 10],\n",
              "       [ 0,  7,  8,  9, 10, 11],\n",
              "       [ 7,  8,  9, 10, 11, 12],\n",
              "       [ 0,  0,  0,  0, 13, 14],\n",
              "       [ 0,  0,  0, 13, 14, 15],\n",
              "       [ 0,  0, 13, 14, 15, 16],\n",
              "       [ 0, 13, 14, 15, 16, 17]], dtype=int32)"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 텍스트 토큰화\n",
        "\n",
        "tok = Tokenizer()\n",
        "tok.fit_on_texts([text])\n",
        "\n",
        "vocSize = len(tok.word_index) + 1\n",
        "\n",
        "seqs = list()\n",
        "for word in text.split('\\n'):\n",
        "    encoded = tok.texts_to_sequences([word])[0]\n",
        "    for i in range(1, len(encoded)):\n",
        "        seq = encoded[:i+1]\n",
        "        seqs.append(seq)\n",
        "\n",
        "maxLen = max(len(i) for i in seqs)\n",
        "\n",
        "seqs = pad_sequences(seqs, maxlen=maxLen, padding=\"pre\")\n",
        "seqs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# x 값에 대한 정의\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "seqs = np.array(seqs)\n",
        "x = seqs[:, :-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# y 값에 대한 정의\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y = seqs[:, -1]\n",
        "y = to_categorical(y, num_classes=vocSize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-20 12:24:21.448927: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
            "2022-05-20 12:24:21.572358: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
            "2022-05-20 12:24:21.616697: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 656ms/step - loss: 2.8901 - accuracy: 0.0714\n",
            "Epoch 2/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.8884 - accuracy: 0.0714\n",
            "Epoch 3/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.8867 - accuracy: 0.0714\n",
            "Epoch 4/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.8850 - accuracy: 0.0714\n",
            "Epoch 5/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.8832 - accuracy: 0.1429\n",
            "Epoch 6/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.8815 - accuracy: 0.1429\n",
            "Epoch 7/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.8797 - accuracy: 0.1429\n",
            "Epoch 8/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.8779 - accuracy: 0.2143\n",
            "Epoch 9/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.8760 - accuracy: 0.2143\n",
            "Epoch 10/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.8741 - accuracy: 0.2143\n",
            "Epoch 11/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.8722 - accuracy: 0.2143\n",
            "Epoch 12/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.8702 - accuracy: 0.2143\n",
            "Epoch 13/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.8681 - accuracy: 0.2143\n",
            "Epoch 14/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.8660 - accuracy: 0.2143\n",
            "Epoch 15/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.8638 - accuracy: 0.2857\n",
            "Epoch 16/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.8616 - accuracy: 0.2857\n",
            "Epoch 17/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.8592 - accuracy: 0.2857\n",
            "Epoch 18/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.8568 - accuracy: 0.2857\n",
            "Epoch 19/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.8543 - accuracy: 0.2857\n",
            "Epoch 20/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.8517 - accuracy: 0.2857\n",
            "Epoch 21/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.8490 - accuracy: 0.2857\n",
            "Epoch 22/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.8461 - accuracy: 0.2857\n",
            "Epoch 23/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.8432 - accuracy: 0.2857\n",
            "Epoch 24/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.8401 - accuracy: 0.2857\n",
            "Epoch 25/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.8369 - accuracy: 0.2857\n",
            "Epoch 26/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.8335 - accuracy: 0.2857\n",
            "Epoch 27/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.8299 - accuracy: 0.2857\n",
            "Epoch 28/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.8263 - accuracy: 0.2857\n",
            "Epoch 29/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.8224 - accuracy: 0.2857\n",
            "Epoch 30/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.8183 - accuracy: 0.2857\n",
            "Epoch 31/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.8141 - accuracy: 0.2857\n",
            "Epoch 32/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.8096 - accuracy: 0.2857\n",
            "Epoch 33/200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.8049 - accuracy: 0.2857\n",
            "Epoch 34/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.7999 - accuracy: 0.2857\n",
            "Epoch 35/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.7948 - accuracy: 0.2857\n",
            "Epoch 36/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.7893 - accuracy: 0.2857\n",
            "Epoch 37/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.7836 - accuracy: 0.2857\n",
            "Epoch 38/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.7775 - accuracy: 0.2857\n",
            "Epoch 39/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.7712 - accuracy: 0.2857\n",
            "Epoch 40/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.7645 - accuracy: 0.2857\n",
            "Epoch 41/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.7575 - accuracy: 0.2857\n",
            "Epoch 42/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.7501 - accuracy: 0.2857\n",
            "Epoch 43/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.7424 - accuracy: 0.2857\n",
            "Epoch 44/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.7342 - accuracy: 0.2857\n",
            "Epoch 45/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.7256 - accuracy: 0.2857\n",
            "Epoch 46/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.7166 - accuracy: 0.2857\n",
            "Epoch 47/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.7072 - accuracy: 0.2857\n",
            "Epoch 48/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.6973 - accuracy: 0.2857\n",
            "Epoch 49/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.6869 - accuracy: 0.2857\n",
            "Epoch 50/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.6761 - accuracy: 0.2857\n",
            "Epoch 51/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.6648 - accuracy: 0.2857\n",
            "Epoch 52/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.6530 - accuracy: 0.2857\n",
            "Epoch 53/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.6407 - accuracy: 0.2857\n",
            "Epoch 54/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.6280 - accuracy: 0.2857\n",
            "Epoch 55/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.6148 - accuracy: 0.2857\n",
            "Epoch 56/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.6011 - accuracy: 0.2857\n",
            "Epoch 57/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.5870 - accuracy: 0.2857\n",
            "Epoch 58/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.5726 - accuracy: 0.3571\n",
            "Epoch 59/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.5577 - accuracy: 0.3571\n",
            "Epoch 60/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.5425 - accuracy: 0.3571\n",
            "Epoch 61/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.5269 - accuracy: 0.3571\n",
            "Epoch 62/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.5109 - accuracy: 0.3571\n",
            "Epoch 63/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.4946 - accuracy: 0.4286\n",
            "Epoch 64/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.4779 - accuracy: 0.4286\n",
            "Epoch 65/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.4608 - accuracy: 0.4286\n",
            "Epoch 66/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.4433 - accuracy: 0.4286\n",
            "Epoch 67/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.4253 - accuracy: 0.4286\n",
            "Epoch 68/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.4069 - accuracy: 0.4286\n",
            "Epoch 69/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.3878 - accuracy: 0.4286\n",
            "Epoch 70/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.3682 - accuracy: 0.4286\n",
            "Epoch 71/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.3480 - accuracy: 0.4286\n",
            "Epoch 72/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.3272 - accuracy: 0.3571\n",
            "Epoch 73/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.3058 - accuracy: 0.3571\n",
            "Epoch 74/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.2837 - accuracy: 0.3571\n",
            "Epoch 75/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.2611 - accuracy: 0.3571\n",
            "Epoch 76/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.2380 - accuracy: 0.3571\n",
            "Epoch 77/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.2143 - accuracy: 0.3571\n",
            "Epoch 78/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.1902 - accuracy: 0.4286\n",
            "Epoch 79/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.1657 - accuracy: 0.4286\n",
            "Epoch 80/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.1410 - accuracy: 0.5000\n",
            "Epoch 81/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.1160 - accuracy: 0.5000\n",
            "Epoch 82/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.0909 - accuracy: 0.5000\n",
            "Epoch 83/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.0656 - accuracy: 0.5000\n",
            "Epoch 84/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.0404 - accuracy: 0.5000\n",
            "Epoch 85/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.0152 - accuracy: 0.5000\n",
            "Epoch 86/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.9901 - accuracy: 0.5000\n",
            "Epoch 87/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.9651 - accuracy: 0.5000\n",
            "Epoch 88/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.9403 - accuracy: 0.6429\n",
            "Epoch 89/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.9156 - accuracy: 0.7143\n",
            "Epoch 90/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.8911 - accuracy: 0.7143\n",
            "Epoch 91/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.8667 - accuracy: 0.7143\n",
            "Epoch 92/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.8425 - accuracy: 0.7143\n",
            "Epoch 93/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.8184 - accuracy: 0.7143\n",
            "Epoch 94/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.7945 - accuracy: 0.7143\n",
            "Epoch 95/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.7707 - accuracy: 0.7143\n",
            "Epoch 96/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.7471 - accuracy: 0.7143\n",
            "Epoch 97/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.7236 - accuracy: 0.7143\n",
            "Epoch 98/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.7002 - accuracy: 0.7143\n",
            "Epoch 99/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.6769 - accuracy: 0.7143\n",
            "Epoch 100/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.6537 - accuracy: 0.7143\n",
            "Epoch 101/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.6308 - accuracy: 0.7143\n",
            "Epoch 102/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.6079 - accuracy: 0.7143\n",
            "Epoch 103/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.5852 - accuracy: 0.7857\n",
            "Epoch 104/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.5627 - accuracy: 0.7857\n",
            "Epoch 105/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.5404 - accuracy: 0.7857\n",
            "Epoch 106/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.5182 - accuracy: 0.8571\n",
            "Epoch 107/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.4962 - accuracy: 0.8571\n",
            "Epoch 108/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.4744 - accuracy: 0.8571\n",
            "Epoch 109/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.4528 - accuracy: 0.8571\n",
            "Epoch 110/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.4314 - accuracy: 0.8571\n",
            "Epoch 111/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.4101 - accuracy: 0.8571\n",
            "Epoch 112/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.3891 - accuracy: 0.8571\n",
            "Epoch 113/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.3683 - accuracy: 0.8571\n",
            "Epoch 114/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.3477 - accuracy: 0.8571\n",
            "Epoch 115/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.3274 - accuracy: 0.8571\n",
            "Epoch 116/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.3073 - accuracy: 0.8571\n",
            "Epoch 117/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.2876 - accuracy: 0.8571\n",
            "Epoch 118/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.2681 - accuracy: 0.8571\n",
            "Epoch 119/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.2490 - accuracy: 0.8571\n",
            "Epoch 120/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.2302 - accuracy: 0.8571\n",
            "Epoch 121/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.2118 - accuracy: 0.8571\n",
            "Epoch 122/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.1936 - accuracy: 0.8571\n",
            "Epoch 123/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.1759 - accuracy: 0.8571\n",
            "Epoch 124/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.1584 - accuracy: 0.8571\n",
            "Epoch 125/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.1413 - accuracy: 0.8571\n",
            "Epoch 126/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.1246 - accuracy: 0.8571\n",
            "Epoch 127/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.1082 - accuracy: 0.8571\n",
            "Epoch 128/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.0921 - accuracy: 0.8571\n",
            "Epoch 129/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.0764 - accuracy: 0.7857\n",
            "Epoch 130/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.0610 - accuracy: 0.7857\n",
            "Epoch 131/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.0460 - accuracy: 0.8571\n",
            "Epoch 132/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.0313 - accuracy: 0.8571\n",
            "Epoch 133/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.0169 - accuracy: 0.8571\n",
            "Epoch 134/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.0028 - accuracy: 0.8571\n",
            "Epoch 135/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.9891 - accuracy: 0.8571\n",
            "Epoch 136/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.9756 - accuracy: 0.8571\n",
            "Epoch 137/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.9624 - accuracy: 0.8571\n",
            "Epoch 138/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.9494 - accuracy: 0.8571\n",
            "Epoch 139/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.9367 - accuracy: 0.8571\n",
            "Epoch 140/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.9242 - accuracy: 0.8571\n",
            "Epoch 141/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.9120 - accuracy: 0.8571\n",
            "Epoch 142/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.9000 - accuracy: 0.8571\n",
            "Epoch 143/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.8882 - accuracy: 0.8571\n",
            "Epoch 144/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.8766 - accuracy: 0.8571\n",
            "Epoch 145/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.8652 - accuracy: 0.8571\n",
            "Epoch 146/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.8541 - accuracy: 0.8571\n",
            "Epoch 147/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.8433 - accuracy: 0.8571\n",
            "Epoch 148/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.8326 - accuracy: 0.8571\n",
            "Epoch 149/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.8222 - accuracy: 0.8571\n",
            "Epoch 150/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.8120 - accuracy: 0.8571\n",
            "Epoch 151/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.8020 - accuracy: 0.8571\n",
            "Epoch 152/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.7923 - accuracy: 0.8571\n",
            "Epoch 153/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.7827 - accuracy: 0.8571\n",
            "Epoch 154/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.7733 - accuracy: 0.8571\n",
            "Epoch 155/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.7640 - accuracy: 0.8571\n",
            "Epoch 156/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.7549 - accuracy: 0.9286\n",
            "Epoch 157/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.7460 - accuracy: 0.9286\n",
            "Epoch 158/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.7373 - accuracy: 0.9286\n",
            "Epoch 159/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.7287 - accuracy: 0.9286\n",
            "Epoch 160/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.7202 - accuracy: 0.9286\n",
            "Epoch 161/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.7119 - accuracy: 0.9286\n",
            "Epoch 162/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.7038 - accuracy: 0.9286\n",
            "Epoch 163/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6958 - accuracy: 0.9286\n",
            "Epoch 164/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6879 - accuracy: 0.9286\n",
            "Epoch 165/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6801 - accuracy: 0.9286\n",
            "Epoch 166/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6725 - accuracy: 0.9286\n",
            "Epoch 167/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6650 - accuracy: 1.0000\n",
            "Epoch 168/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6576 - accuracy: 1.0000\n",
            "Epoch 169/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6502 - accuracy: 1.0000\n",
            "Epoch 170/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6430 - accuracy: 1.0000\n",
            "Epoch 171/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6359 - accuracy: 1.0000\n",
            "Epoch 172/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6288 - accuracy: 1.0000\n",
            "Epoch 173/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6219 - accuracy: 1.0000\n",
            "Epoch 174/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6151 - accuracy: 1.0000\n",
            "Epoch 175/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6084 - accuracy: 1.0000\n",
            "Epoch 176/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6017 - accuracy: 1.0000\n",
            "Epoch 177/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.5952 - accuracy: 1.0000\n",
            "Epoch 178/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.5888 - accuracy: 1.0000\n",
            "Epoch 179/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5824 - accuracy: 1.0000\n",
            "Epoch 180/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5761 - accuracy: 1.0000\n",
            "Epoch 181/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5699 - accuracy: 1.0000\n",
            "Epoch 182/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.5638 - accuracy: 1.0000\n",
            "Epoch 183/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5578 - accuracy: 1.0000\n",
            "Epoch 184/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5519 - accuracy: 1.0000\n",
            "Epoch 185/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.5460 - accuracy: 1.0000\n",
            "Epoch 186/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5402 - accuracy: 1.0000\n",
            "Epoch 187/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5345 - accuracy: 1.0000\n",
            "Epoch 188/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.5288 - accuracy: 1.0000\n",
            "Epoch 189/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5233 - accuracy: 1.0000\n",
            "Epoch 190/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.5178 - accuracy: 1.0000\n",
            "Epoch 191/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.5123 - accuracy: 1.0000\n",
            "Epoch 192/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5069 - accuracy: 1.0000\n",
            "Epoch 193/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5016 - accuracy: 1.0000\n",
            "Epoch 194/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.4964 - accuracy: 1.0000\n",
            "Epoch 195/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.4912 - accuracy: 1.0000\n",
            "Epoch 196/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.4861 - accuracy: 1.0000\n",
            "Epoch 197/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.4810 - accuracy: 1.0000\n",
            "Epoch 198/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.4760 - accuracy: 1.0000\n",
            "Epoch 199/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.4710 - accuracy: 1.0000\n",
            "Epoch 200/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.4661 - accuracy: 1.0000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x28b8d10a0>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 모델 생성 및 훈련\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "from tensorflow.keras.layers import Embedding\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocSize, 10, input_length=maxLen-1,))\n",
        "model.add(LSTM(32))\n",
        "model.add(Dense(vocSize, activation=\"softmax\"))\n",
        "model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=\"adam\")\n",
        "model.fit(x, y, epochs=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 단어 예측\n",
        "\n",
        "def sentGen(model, tok, word, n):\n",
        "    sent = \"\"\n",
        "    word2 = word\n",
        "    for _ in range(n):\n",
        "        encoded = tok.texts_to_sequences([word])[0]\n",
        "        encoded = pad_sequences([encoded], maxlen=5, padding=\"pre\")\n",
        "        res = np.argmax(model.predict(encoded))\n",
        "\n",
        "        for w, i in tok.word_index.items():\n",
        "            if i == res:\n",
        "                break\n",
        "        \n",
        "        word = word + \" \" + w\n",
        "        sent = sent + \" \" + w\n",
        "    \n",
        "    sent = word2 + sent\n",
        "\n",
        "    return sent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "과일 가게에 사과가 많이 진열되어 있다\n"
          ]
        }
      ],
      "source": [
        "# '과일' 이후의 예측 단어\n",
        "\n",
        "print(sentGen(model, tok, \"과일\", 5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Chapter10.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "16ff67ac5b59543b0cabf8c01bdd6301311b1b38ea29649e2dcd267ea06ee271"
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 ('tf3.8')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
