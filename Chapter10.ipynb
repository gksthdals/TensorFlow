{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTJB2UgUbLS-"
      },
      "source": [
        "# 10.1 Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1prEpDaubVGs"
      },
      "outputs": [],
      "source": [
        "# 단어 및 문장 간 관련성 계산\n",
        "# 의미적 혹은 문법적 정보의 함축"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aM4LAKsWb09n"
      },
      "source": [
        "## 10.1.1 Sparse Representation based Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxEXw14qb7ZL",
        "outputId": "c5003b12-ea14-498f-c320-ce90e11c9143"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([2, 2, 1, 0, 1, 0])"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "class2 = pd.read_csv('data/chap10/class2.csv')\n",
        "\n",
        "from sklearn import preprocessing\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "onehot_encoder = preprocessing.OneHotEncoder()\n",
        "\n",
        "train_x = label_encoder.fit_transform(class2['class2'])\n",
        "train_x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cfnyl8WjccQM"
      },
      "outputs": [],
      "source": [
        "\"\"\" One-hot Encoding의 단점 \n",
        "\n",
        "1. 단어끼리의 관계성(유의어, 반의어) 업이 서로 독립적인 관계\n",
        "2. 차원이 너무 커지는 문제가 발생\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5o-rUqHNcy1r"
      },
      "source": [
        "## 10.1.2 Counting based Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49hzdW3_c8gR",
        "outputId": "ca84c159-abaa-47a1-ebd6-6f2d616305ed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'this': 13,\n",
              " 'is': 7,\n",
              " 'last': 8,\n",
              " 'chance': 2,\n",
              " 'and': 0,\n",
              " 'if': 6,\n",
              " 'you': 15,\n",
              " 'do': 3,\n",
              " 'not': 10,\n",
              " 'have': 5,\n",
              " 'will': 14,\n",
              " 'never': 9,\n",
              " 'get': 4,\n",
              " 'any': 1,\n",
              " 'one': 11,\n",
              " 'please': 12}"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Corpus에 counter vector 적용\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "corpus = [\n",
        "          'This is last chance.',\n",
        "          'and if you do not have this chance.',\n",
        "          'you will never get any chance.',\n",
        "          'will you do get this one?',\n",
        "          'please, get this chance',\n",
        "]\n",
        "\n",
        "vect = CountVectorizer()\n",
        "vect.fit(corpus)\n",
        "vect.vocabulary_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIznLqB8derw",
        "outputId": "4b596fed-83e8-4f5d-9e50-54000e8cf94a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1]])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vect.transform(['you will never get any chance.']).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50YDT4vndpV9",
        "outputId": "30481145-e86d-42c5-82fd-c4793b74d914"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'last': 6,\n",
              " 'chance': 1,\n",
              " 'if': 5,\n",
              " 'you': 11,\n",
              " 'do': 2,\n",
              " 'not': 8,\n",
              " 'have': 4,\n",
              " 'will': 10,\n",
              " 'never': 7,\n",
              " 'get': 3,\n",
              " 'any': 0,\n",
              " 'one': 9}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vect = CountVectorizer(stop_words=[\"and\", \"is\", \"please\", \"this\"]).fit(corpus)\n",
        "vect.vocabulary_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TQCIc-J0d54E"
      },
      "outputs": [],
      "source": [
        "# TF-IDF : Term Frequency-Inverse Document Frequency\n",
        "\n",
        "# TF : 특정 문서 d에서 특정 단어 t의 등장 횟수\n",
        "# DF : 특정 단어 t가가 포함된 문서 개수\n",
        "# IDF : Inverse Document Frequency\n",
        "\n",
        "# 키워드 검색을 기반으로 하는 검색 엔진\n",
        "# 중요 키워드 분석\n",
        "# 검색 엔진에서 검색 결과의 순위를 결정 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDZoixx93kAN",
        "outputId": "66855650-ff50-4964-991c-7a2e09188fb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "유사도를 위한 3 x 3 행렬을 만들었습니다.\n",
            "[[1.       0.224325 0.      ]\n",
            " [0.224325 1.       0.      ]\n",
            " [0.       0.       1.      ]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "doc = ['I like machine learning', 'I love deep learning', 'I run everyday']\n",
        "tfidf_vectorizer = TfidfVectorizer(min_df=1)\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(doc)\n",
        "doc_distance = (tfidf_matrix * tfidf_matrix.T)\n",
        "print('유사도를 위한', str(doc_distance.get_shape()[0]), 'x', str(doc_distance.get_shape()[1]), '행렬을 만들었습니다.')\n",
        "print(doc_distance.toarray())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RntYOCZv5Kkx"
      },
      "source": [
        "## 10.1.3 Prediction based Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Popi2GGj6D3c"
      },
      "source": [
        "### Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3H_6zHpI6ptE",
        "outputId": "729c251d-3c95-416e-eda7-53babeaf619f"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYP2atDO5hj4",
        "outputId": "e6ad7036-1d9b-4ac9-f083-5f7f3a7e8e7c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['once',\n",
              " 'upon',\n",
              " 'a',\n",
              " 'time',\n",
              " 'in',\n",
              " 'london',\n",
              " ',',\n",
              " 'the',\n",
              " 'darlings',\n",
              " 'went',\n",
              " 'out',\n",
              " 'to',\n",
              " 'a',\n",
              " 'dinner',\n",
              " 'party',\n",
              " 'leaving',\n",
              " 'their',\n",
              " 'three',\n",
              " 'children',\n",
              " 'wendy',\n",
              " ',',\n",
              " 'jhon',\n",
              " ',',\n",
              " 'and',\n",
              " 'michael',\n",
              " 'at',\n",
              " 'home',\n",
              " '.']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "sample = open('/content/peter.txt', \"r\", encoding='UTF8')\n",
        "s = sample.read()\n",
        "\n",
        "f = s.replace('\\n', ' ')\n",
        "data = []\n",
        "\n",
        "for i in sent_tokenize(f):\n",
        "  temp = []\n",
        "  for j in word_tokenize(i):\n",
        "    temp.append(j.lower())\n",
        "  data.append(temp)\n",
        "\n",
        "data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGU4CHIZ632u",
        "outputId": "133b4f43-e8f2-434d-bf25-12efdeb13c62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cosine similarity between 'peter' 'wendy' - CBOW :  -0.059717968\n"
          ]
        }
      ],
      "source": [
        "model1 = gensim.models.Word2Vec(data, min_count=1, size=100, window=5, sg=0)\n",
        "print(\"Cosine similarity between 'peter' \" + \"'wendy' - CBOW : \", model1.similarity('peter', 'wendy'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZ0OhV027qfF",
        "outputId": "9d14a87e-78df-42e2-e165-e6707134eb16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cosine similarity between 'peter' 'hook' - CBOW :  0.17057094\n"
          ]
        }
      ],
      "source": [
        "print(\"Cosine similarity between 'peter' \" + \"'hook' - CBOW : \", model1.similarity('peter', 'hook'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBhlh6GA8va3",
        "outputId": "2a27c1c9-64d1-4831-bc1a-af8529341980"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cosine similarity between 'peter' 'wendy' - Skip Gram :  0.23208164\n"
          ]
        }
      ],
      "source": [
        "model2 = gensim.models.Word2Vec(data, min_count=1, size=100, window=5, sg=1)\n",
        "print(\"Cosine similarity between 'peter' \" + \"'wendy' - Skip Gram : \", model2.similarity('peter', 'wendy'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UV39C4XE9HGh",
        "outputId": "5890ccc8-0f40-4525-f6b9-33c3e81678d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cosine similarity between 'peter' 'hook' - Skip Gram :  0.5484486\n"
          ]
        }
      ],
      "source": [
        "print(\"Cosine similarity between 'peter' \" + \"'hook' - Skip Gram : \", model2.similarity('peter', 'hook'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Iienpdan9SrG"
      },
      "outputs": [],
      "source": [
        "from gensim.test.utils import common_texts\n",
        "from gensim.models import FastText\n",
        "\n",
        "model = FastText(data, size=4, window=3, min_count=1, iter=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFo_T9gB93oe",
        "outputId": "d6e60d9e-a1a2-4577-fb30-78623037e5fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.6989395\n"
          ]
        }
      ],
      "source": [
        "sim_score = model.wv.similarity('peter', 'wendy')\n",
        "print(sim_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xknByRJc-AwC",
        "outputId": "6e4147c3-5cc4-4f14-9dee-222a611e9020"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.23571663\n"
          ]
        }
      ],
      "source": [
        "sim_score = model.wv.similarity('peter', 'hook')\n",
        "print(sim_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "k7iHomsV_bO5"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "model_kr = KeyedVectors.load_word2vec_format('data/chap10/wiki.ko.vec')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "anGfbGKa_1sq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word: 노력함, Similarity: 0.80\n",
            "Word: 노력중, Similarity: 0.75\n",
            "Word: 노력만, Similarity: 0.72\n",
            "Word: 노력과, Similarity: 0.71\n",
            "Word: 노력의, Similarity: 0.69\n",
            "Word: 노력가, Similarity: 0.69\n",
            "Word: 노력이나, Similarity: 0.69\n",
            "Word: 노력없이, Similarity: 0.68\n",
            "Word: 노력맨, Similarity: 0.68\n",
            "Word: 노력보다는, Similarity: 0.68\n"
          ]
        }
      ],
      "source": [
        "find_similar_to = '노력'\n",
        "\n",
        "for similar_word in model_kr.similar_by_word(find_similar_to):\n",
        "  print(\"Word: {0}, Similarity: {1:.2f}\".format(\n",
        "      similar_word[0], similar_word[1]\n",
        "  ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jS4Z7ybSAFYV"
      },
      "outputs": [],
      "source": [
        "similarities = model_kr.wv.most_similar(positive=['동물', '육식동물'], negative=['사람'])\n",
        "print(similarities)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3zTGBgWDac1"
      },
      "source": [
        "## 10.1.4 Counting/Prediction based Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-CYZwznDezV"
      },
      "outputs": [],
      "source": [
        "# GloVe: Global Vectors for Word Representation\n",
        "\n",
        "# LSA : Latent Semantic Analysis\n",
        "# Word2Vec\n",
        "# 두 Models의 단점을 보완"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "id": "m7sU0ol-EMKy",
        "outputId": "75f96599-b359-40a4-9eb2-c23c945966fb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/lt/7j3txvvn1bgc84pp3c9kldcw0000gn/T/ipykernel_3343/2418356103.py:12: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
            "  glove2word2vec(glove_file, word2vec_glove_file)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(400000, 100)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "%matplotlib notebook\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "from sklearn.decomposition import PCA\n",
        "from gensim.test.utils import datapath, get_tmpfile\n",
        "from gensim.models import KeyedVectors\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "\n",
        "glove_file = datapath('/Users/mini/TensorFlow/data/chap10/glove.6B.100d.txt')\n",
        "word2vec_glove_file = get_tmpfile(\"/Users/mini/TensorFlow/data/chap10/glove.6B.100d.txt\")\n",
        "glove2word2vec(glove_file, word2vec_glove_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "jcXRpUhXE1lt"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('legislation', 0.8072139620780945),\n",
              " ('proposal', 0.7306863069534302),\n",
              " ('senate', 0.7142540812492371),\n",
              " ('bills', 0.704440176486969),\n",
              " ('measure', 0.6958035230636597),\n",
              " ('passed', 0.6906244158744812),\n",
              " ('amendment', 0.6846879720687866),\n",
              " ('provision', 0.6845566630363464),\n",
              " ('plan', 0.6816462874412537),\n",
              " ('clinton', 0.6663140058517456)]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = KeyedVectors.load_word2vec_format(word2vec_glove_file)\n",
        "model.most_similar('bill')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "KJESsjBYFdaf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('peach', 0.688809871673584),\n",
              " ('mango', 0.6838189959526062),\n",
              " ('plum', 0.6684104204177856),\n",
              " ('berry', 0.659035861492157),\n",
              " ('grove', 0.6581552028656006),\n",
              " ('blossom', 0.6503506302833557),\n",
              " ('raspberry', 0.6477391123771667),\n",
              " ('strawberry', 0.6442098021507263),\n",
              " ('pine', 0.6390928626060486),\n",
              " ('almond', 0.6379212141036987)]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.most_similar('cherry')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "zJjYhOgbFf-k"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('kazushige', 0.4834350347518921),\n",
              " ('askerov', 0.4778185784816742),\n",
              " ('lakpa', 0.46915262937545776),\n",
              " ('ex-gay', 0.45713332295417786),\n",
              " ('tadayoshi', 0.4522107243537903),\n",
              " ('turani', 0.44810065627098083),\n",
              " ('saglam', 0.4469599425792694),\n",
              " ('aijun', 0.4435270130634308),\n",
              " ('adjustors', 0.44235295057296753),\n",
              " ('nyum', 0.4423117935657501)]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.most_similar(negative=['cherry'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "1DOiUqm8FkAX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "queen: 0.7699\n"
          ]
        }
      ],
      "source": [
        "result = model.most_similar(positive=['woman', 'king'], negative=['man'])\n",
        "print(\"{}: {:.4f}\".format(*result[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Lp9kQ8a7Ft-s"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'champagne'"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def analogy(x1, x2, y1):\n",
        "  result = model.most_similar(positive=[y1, x2], negative=[x1])\n",
        "  return result[0][0]\n",
        "\n",
        "analogy('australia', 'beer', 'france')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "emyGPwCsF7TQ"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'longest'"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "analogy('tall', 'tallest', 'long')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "XIdSMZ-_F98k"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cereal\n"
          ]
        }
      ],
      "source": [
        "print(model.doesnt_match('breakfast cereal dinner lunch'.split()))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Chapter10.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "16ff67ac5b59543b0cabf8c01bdd6301311b1b38ea29649e2dcd267ea06ee271"
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 ('tf3.8')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
